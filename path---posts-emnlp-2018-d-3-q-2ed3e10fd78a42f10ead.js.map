{"version":3,"sources":["webpack:///path---posts-emnlp-2018-d-3-q-2ed3e10fd78a42f10ead.js","webpack:///./.cache/json/posts-emnlp-2018-d-3-q.json"],"names":["webpackJsonp","404","module","exports","data","site","siteMetadata","title","subtitle","copyright","author","name","twitter","disqusShortname","url","markdownRemark","id","html","fields","tagSlugs","frontmatter","tags","date","description","conference","pathContext","slug"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,MAAQC,cAAgBC,MAAA,cAAAC,SAAA,wIAAAC,UAAA,yBAAAC,QAAwNC,KAAA,cAAAC,QAAA,KAAmCC,gBAAA,GAAAC,IAAA,8BAAyDC,gBAAmBC,GAAA,iIAAAC,KAAA,8lCAAAC,QAA6vCC,UAAA,6EAAwFC,aAAgBb,MAAA,2EAAAc,MAAA,uDAAAC,KAAA,2BAAAC,YAAA,uEAAAC,WAAA,gBAAqSC,aAAgBC,KAAA","file":"path---posts-emnlp-2018-d-3-q-2ed3e10fd78a42f10ead.js","sourcesContent":["webpackJsonp([89210907246003],{\n\n/***/ 404:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"site\":{\"siteMetadata\":{\"title\":\"Shang-Yu Su\",\"subtitle\":\"PhD student in National Taiwan University, research interests cover Deep Learning, Natural Language Processing, and dialogue systems.\",\"copyright\":\"© All rights reserved.\",\"author\":{\"name\":\"Shang-Yu Su\",\"twitter\":\"#\"},\"disqusShortname\":\"\",\"url\":\"https://www.shangyusu.com\"}},\"markdownRemark\":{\"id\":\"/Users/ShangYu/Desktop/github/shangyusu.github.io/src/pages/articles/EMNLP2018-D3Q/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p><b>This paper is published in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP 2018).</b></p>\\n<p>Full paper:\\n<a href=\\\"/emnlp-2018-d3q-b71cd121612e0c757f51ccd99c6b5480.pdf\\\" target=\\\"_blank\\\">Here</a>,\\n<a href=\\\"https://arxiv.org/abs/1808.09442\\\" target=\\\"_blank\\\">arXiv</a></p>\\n<p>This paper presents a Discriminative Deep Dyna-Q (D3Q) approach to improving the effectiveness and robustness of DDQ, a recently proposed framework that extends the Dyna-Q algorithm to integrate planning for task-completion dialogue policy learning. To obviate DDQ’s high dependency on the quality of simulated experiences, we incorporate an RNN-based discriminator in D3Q to differentiate simulated experience from real user experience in order to control the quality of training data. Experiments show that D3Q significantly outperforms DDQ by controlling the quality of simulated experience used for planning. The effectiveness and robustness of D3Q is further demonstrated in a domain extension setting, where the agent’s capability of adapting to a changing environment is tested.</p>\",\"fields\":{\"tagSlugs\":[\"/tags/dialogue/\",\"/tags/dialogue-policy/\",\"/tags/reinforcement-learning/\"]},\"frontmatter\":{\"title\":\"Discriminative Deep Dyna-Q: Robust Planning for Dialogue Policy Learning\",\"tags\":[\"Dialogue\",\"Dialogue Policy\",\"Reinforcement Learning\"],\"date\":\"2018-08-13T22:40:32.169Z\",\"description\":\"Shang-Yu Su, Xiujun Li, Jianfeng Gao, Jingjing Liu and Yun-Nung Chen\",\"conference\":\"EMNLP 2018\"}}},\"pathContext\":{\"slug\":\"/posts/emnlp2018-d3q/\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---posts-emnlp-2018-d-3-q-2ed3e10fd78a42f10ead.js","module.exports = {\"data\":{\"site\":{\"siteMetadata\":{\"title\":\"Shang-Yu Su\",\"subtitle\":\"PhD student in National Taiwan University, research interests cover Deep Learning, Natural Language Processing, and dialogue systems.\",\"copyright\":\"© All rights reserved.\",\"author\":{\"name\":\"Shang-Yu Su\",\"twitter\":\"#\"},\"disqusShortname\":\"\",\"url\":\"https://www.shangyusu.com\"}},\"markdownRemark\":{\"id\":\"/Users/ShangYu/Desktop/github/shangyusu.github.io/src/pages/articles/EMNLP2018-D3Q/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p><b>This paper is published in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP 2018).</b></p>\\n<p>Full paper:\\n<a href=\\\"/emnlp-2018-d3q-b71cd121612e0c757f51ccd99c6b5480.pdf\\\" target=\\\"_blank\\\">Here</a>,\\n<a href=\\\"https://arxiv.org/abs/1808.09442\\\" target=\\\"_blank\\\">arXiv</a></p>\\n<p>This paper presents a Discriminative Deep Dyna-Q (D3Q) approach to improving the effectiveness and robustness of DDQ, a recently proposed framework that extends the Dyna-Q algorithm to integrate planning for task-completion dialogue policy learning. To obviate DDQ’s high dependency on the quality of simulated experiences, we incorporate an RNN-based discriminator in D3Q to differentiate simulated experience from real user experience in order to control the quality of training data. Experiments show that D3Q significantly outperforms DDQ by controlling the quality of simulated experience used for planning. The effectiveness and robustness of D3Q is further demonstrated in a domain extension setting, where the agent’s capability of adapting to a changing environment is tested.</p>\",\"fields\":{\"tagSlugs\":[\"/tags/dialogue/\",\"/tags/dialogue-policy/\",\"/tags/reinforcement-learning/\"]},\"frontmatter\":{\"title\":\"Discriminative Deep Dyna-Q: Robust Planning for Dialogue Policy Learning\",\"tags\":[\"Dialogue\",\"Dialogue Policy\",\"Reinforcement Learning\"],\"date\":\"2018-08-13T22:40:32.169Z\",\"description\":\"Shang-Yu Su, Xiujun Li, Jianfeng Gao, Jingjing Liu and Yun-Nung Chen\",\"conference\":\"EMNLP 2018\"}}},\"pathContext\":{\"slug\":\"/posts/emnlp2018-d3q/\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/posts-emnlp-2018-d-3-q.json\n// module id = 404\n// module chunks = 89210907246003"],"sourceRoot":""}