{"version":3,"sources":["webpack:///path---publications-phd-thesis-0af8b5c8e3d514ab4ad2.js","webpack:///./.cache/json/publications-phd-thesis.json"],"names":["webpackJsonp","476","module","exports","data","site","siteMetadata","title","subtitle","copyright","author","name","twitter","disqusShortname","url","markdownRemark","id","html","fields","tagSlugs","frontmatter","tags","date","description","conference","pathContext","slug"],"mappings":"AAAAA,cAAc,gBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,MAAQC,cAAgBC,MAAA,cAAAC,SAAA,6CAAAC,UAAA,yBAAAC,QAA6HC,KAAA,cAAAC,QAAA,KAAmCC,gBAAA,GAAAC,IAAA,8BAAyDC,gBAAmBC,GAAA,8HAAAC,KAAA,02FAAksBC,QAA40EC,UAAA,gIAA2IC,aAAgBb,MAAA,kFAAAc,MAAA,mGAAAC,KAAA,2BAAAC,YAAA,cAAAC,WAAA,gBAA+RC,aAAgBC,KAAA","file":"path---publications-phd-thesis-0af8b5c8e3d514ab4ad2.js","sourcesContent":["webpackJsonp([1150569112720],{\n\n/***/ 476:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"site\":{\"siteMetadata\":{\"title\":\"Shang-Yu Su\",\"subtitle\":\"Researcher of Natural Language Processing.\",\"copyright\":\"© All rights reserved.\",\"author\":{\"name\":\"Shang-Yu Su\",\"twitter\":\"#\"},\"disqusShortname\":\"\",\"url\":\"https://www.shangyusu.com\"}},\"markdownRemark\":{\"id\":\"/Users/ShangYu/Desktop/github/shangyusu.github.io/src/pages/articles/PHD-THESIS/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p><b>This thesis was recognized by <a href=\\\"https://www.aclclp.org.tw/grants_c.php\\\" target=\\\"_blank\\\">ACLCLP Best Thesis Award (2022)</a>.</b></p>\\n<p>Resources:\\n<a href=\\\"/PhD_Thesis_Shang_Yu_Su_cover-b1275b0ca06ec8e1ed840c18c7776f6c.pdf\\\" target=\\\"_blank\\\">full thesis</a>,\\n<a href=\\\"https://etds.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=6nzfZD/record?r1=1&h1=1\\\" target=\\\"_blank\\\">NDLTD</a>,\\n<a href=\\\"/defense_v1.0-002974f812bdd246cf6abe35d0efdf25.pdf\\\" target=\\\"_blank\\\">slides</a>.</p>\\n<p>Many real­world artificial intelligence tasks come with a dual form; that is, we could\\ndirectly swap the input and the target of a task to formulate another task. Machine translation is a classic example, for example, translating from English to Chinese has a dual task\\nof translating from Chinese to English. Automatic speech recognition (ASR) and text­-to-speech (TTS) also have structural duality. Given a piece of informative context, question\\nanswering and question generation are in dual form. The recent studies magnified the importance of the duality by boosting the performance of both tasks with the exploitation of the duality.</p>\\n<p>Natural language understanding (NLU) and natural language generation (NLG) are\\nboth critical research topics in the NLP and dialogue fields. The goal of natural language understanding is to extract the core semantic meaning from the given utterances, while\\nnatural language generation is opposite, of which the goal is to construct corresponding\\nsentences based on the given semantics. However, the dual property between understanding and generation has been rarely explored.</p>\\n<p>This main goal of this dissertation is to investigate the structural duality between NLU\\nand NLG. In this thesis, we present five consecutive studies, each focuses on different\\naspects of learning and data settings. First, we exploits the duality between NLU and\\nNLG and introduces it into the learning objective as the regularization term. Moreover,\\nexpert knowledge is incorporated to design suitable approaches for estimating data distribution. Second, we further propose a joint learning framework, which provides flexibility of incorporating not only supervised but also unsupervised learning algorithms and enables the gradient to propagate through two modules seamlessly. Third, we study how to\\nenhance the joint framework by mutual information maximization. Fourth, since above\\nworks exploit the duality in the training stage, hence we make a step forward to leverage\\nthe duality in the inference stage. Lastly, we finetune the pretrained language models on\\nthe two dual tasks and achieve the goal of solving two dual tasks in a single model. Each\\nwork presents a new model and learning framework exploiting the duality in different\\nmanners. Together, this dissertation explores a new research direction of exploiting the\\nduality between language understanding and generation.</p>\",\"fields\":{\"tagSlugs\":[\"/tags/dialogue-systems/\",\"/tags/natural-language-understanding/\",\"/tags/natural-language-generation/\",\"/tags/dual-learning/\"]},\"frontmatter\":{\"title\":\"Exploiting the Duality between Language Understanding and Generation and Beyond\",\"tags\":[\"Dialogue Systems\",\"Natural Language Understanding\",\"Natural Language Generation\",\"Dual Learning\"],\"date\":\"2021-10-19T22:40:32.169Z\",\"description\":\"Shang-Yu Su\",\"conference\":\"PhD Thesis\"}}},\"pathContext\":{\"slug\":\"/publications/phd-thesis/\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---publications-phd-thesis-0af8b5c8e3d514ab4ad2.js","module.exports = {\"data\":{\"site\":{\"siteMetadata\":{\"title\":\"Shang-Yu Su\",\"subtitle\":\"Researcher of Natural Language Processing.\",\"copyright\":\"© All rights reserved.\",\"author\":{\"name\":\"Shang-Yu Su\",\"twitter\":\"#\"},\"disqusShortname\":\"\",\"url\":\"https://www.shangyusu.com\"}},\"markdownRemark\":{\"id\":\"/Users/ShangYu/Desktop/github/shangyusu.github.io/src/pages/articles/PHD-THESIS/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p><b>This thesis was recognized by <a href=\\\"https://www.aclclp.org.tw/grants_c.php\\\" target=\\\"_blank\\\">ACLCLP Best Thesis Award (2022)</a>.</b></p>\\n<p>Resources:\\n<a href=\\\"/PhD_Thesis_Shang_Yu_Su_cover-b1275b0ca06ec8e1ed840c18c7776f6c.pdf\\\" target=\\\"_blank\\\">full thesis</a>,\\n<a href=\\\"https://etds.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=6nzfZD/record?r1=1&h1=1\\\" target=\\\"_blank\\\">NDLTD</a>,\\n<a href=\\\"/defense_v1.0-002974f812bdd246cf6abe35d0efdf25.pdf\\\" target=\\\"_blank\\\">slides</a>.</p>\\n<p>Many real­world artificial intelligence tasks come with a dual form; that is, we could\\ndirectly swap the input and the target of a task to formulate another task. Machine translation is a classic example, for example, translating from English to Chinese has a dual task\\nof translating from Chinese to English. Automatic speech recognition (ASR) and text­-to-speech (TTS) also have structural duality. Given a piece of informative context, question\\nanswering and question generation are in dual form. The recent studies magnified the importance of the duality by boosting the performance of both tasks with the exploitation of the duality.</p>\\n<p>Natural language understanding (NLU) and natural language generation (NLG) are\\nboth critical research topics in the NLP and dialogue fields. The goal of natural language understanding is to extract the core semantic meaning from the given utterances, while\\nnatural language generation is opposite, of which the goal is to construct corresponding\\nsentences based on the given semantics. However, the dual property between understanding and generation has been rarely explored.</p>\\n<p>This main goal of this dissertation is to investigate the structural duality between NLU\\nand NLG. In this thesis, we present five consecutive studies, each focuses on different\\naspects of learning and data settings. First, we exploits the duality between NLU and\\nNLG and introduces it into the learning objective as the regularization term. Moreover,\\nexpert knowledge is incorporated to design suitable approaches for estimating data distribution. Second, we further propose a joint learning framework, which provides flexibility of incorporating not only supervised but also unsupervised learning algorithms and enables the gradient to propagate through two modules seamlessly. Third, we study how to\\nenhance the joint framework by mutual information maximization. Fourth, since above\\nworks exploit the duality in the training stage, hence we make a step forward to leverage\\nthe duality in the inference stage. Lastly, we finetune the pretrained language models on\\nthe two dual tasks and achieve the goal of solving two dual tasks in a single model. Each\\nwork presents a new model and learning framework exploiting the duality in different\\nmanners. Together, this dissertation explores a new research direction of exploiting the\\nduality between language understanding and generation.</p>\",\"fields\":{\"tagSlugs\":[\"/tags/dialogue-systems/\",\"/tags/natural-language-understanding/\",\"/tags/natural-language-generation/\",\"/tags/dual-learning/\"]},\"frontmatter\":{\"title\":\"Exploiting the Duality between Language Understanding and Generation and Beyond\",\"tags\":[\"Dialogue Systems\",\"Natural Language Understanding\",\"Natural Language Generation\",\"Dual Learning\"],\"date\":\"2021-10-19T22:40:32.169Z\",\"description\":\"Shang-Yu Su\",\"conference\":\"PhD Thesis\"}}},\"pathContext\":{\"slug\":\"/publications/phd-thesis/\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/publications-phd-thesis.json\n// module id = 476\n// module chunks = 1150569112720"],"sourceRoot":""}