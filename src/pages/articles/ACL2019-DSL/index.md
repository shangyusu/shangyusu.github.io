---
title: "Dual Supervised Learning for Natural Language Understanding and Generation"
date: "2019-05-17T22:40:32.169Z"
layout: post
draft: false
path: "/posts/acl2019-dsl/"
category: "NLU+NLG"
conference: "ACL2019"
tags:
  - "NLU"
  - "NLG"
  - "Dialogue"
description: "Shang-Yu Su, Chao-Wei Huang, and Yun-Nung Chen"
---

<b>This paper is published in Proceedings of The 57th Annual Meeting of the Association for Computational Linguistics (ACL).</b>


Full paper:
<a href="./ACL_2019___Dual_Supervised_Learning.pdf" target="_blank">Here</a>,
<a href="https://arxiv.org/abs/1905.06196" target="_blank">arXiv</a>


Natural language understanding (NLU) and natural language generation (NLG) are both critical research topics in the NLP field.
Natural language understanding is to extract the core semantic meaning from the given utterances, while natural language generation is opposite, of which the goal is to construct corresponding sentences based on the given semantics. 
However, such dual relationship has not been investigated in the literature.
This paper proposes a new learning framework for language understanding and generation on top of dual supervised learning, providing a way to exploit the duality.
The preliminary experiments show that the proposed approach boosts the performance for both tasks. 